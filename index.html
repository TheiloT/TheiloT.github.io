<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="Sky-NeRF - Theïlo Terrisse, Dawa Derksen, David Youssefi, Hugo Meric">
  <meta name="description" content="We present Sky-NeRF, a novel method for cloud topography estimation based on Dynamic Neural Radiance Fields. Similar to NeRF, we propose to model the 3D structure of clouds as a radiance field, encoded in the parameters of a neural representation. Our goal is to reconstruct the 3D geometry, appearance, and motion of the cloud using a stereo-video of high-resolution top of the atmosphere radiance images. In this paper, we evaluate a novel way of modeling the dynamic behavior of clouds, with the goal of extracting added-value physical information regarding the cloud such as advection speed and direction, velocity field and cloud trajectories. We investigate how to include a simple physical prior, advection, into the learning system and evaluate its impact. Our results show that Sky-NeRF is able to provide a more complete 4D reconstruction than traditional stereo-matching-based algorithms. Moreover, thanks to a physics-based interpolation, Sky-NeRF is able to generate coherent new images from unseen viewing angles, and at any time between the observed frames.">
  <meta name="keywords" content="Cloud Topography, Trajectory Estimation, 4D Reconstruction, Dynamic Neural Radiance Fields, Physics-Inspired Deep Learning">
  <meta name="author" content="Theïlo Terrisse, Dawa Derksen, David Youssefi, Hugo Meric">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="CS, CNES">
  <meta property="og:title" content="Sky-NeRF - Theïlo Terrisse, Dawa Derksen, David Youssefi, Hugo Meric">
  <meta property="og:description" content="We present Sky-NeRF, a novel method for cloud topography estimation based on Dynamic Neural Radiance Fields. Similar to NeRF, we propose to model the 3D structure of clouds as a radiance field, encoded in the parameters of a neural representation. Our goal is to reconstruct the 3D geometry, appearance, and motion of the cloud using a stereo-video of high-resolution top of the atmosphere radiance images. In this paper, we evaluate a novel way of modeling the dynamic behavior of clouds, with the goal of extracting added-value physical information regarding the cloud such as advection speed and direction, velocity field and cloud trajectories. We investigate how to include a simple physical prior, advection, into the learning system and evaluate its impact. Our results show that Sky-NeRF is able to provide a more complete 4D reconstruction than traditional stereo-matching-based algorithms. Moreover, thanks to a physics-based interpolation, Sky-NeRF is able to generate coherent new images from unseen viewing angles, and at any time between the observed frames.">
  <meta property="og:url" content="https://theilot.github.io/">
  <meta property="og:image" content="https://YOUR_DOMAIN.com/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="Sky-NeRF - Research Preview">
  <meta property="article:published_time" content="2026-07-04T00:00:00.000Z">
  <meta property="article:author" content="Theïlo Terrisse">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Cloud Topography">
  <meta property="article:tag" content="Dynamic Neural Radiance Fields">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="Sky-NeRF">
  <meta name="citation_author" content="Terrisse, Theïlo">
  <meta name="citation_author" content="Derksen, Dawa">
  <meta name="citation_author" content="Youssefi, David">
  <meta name="citation_author" content="Meric, Hugo">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="XXV ISPRS Congress">
  <meta name="citation_pdf_url" content="https://TheiloT.github.io/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">

  <!-- Title -->
  <title>Sky-NeRF</title>
  
  <!-- Favicon and App Icons -->
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link rel="apple-touch-icon" href="static/images/favicon.ico">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  <link rel="stylesheet" href="static/css/dics-original.css">

  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  <script defer src="static/js/dics-original.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/img-comparison-slider@8/dist/index.js"></script>
  
  <!-- Instantiate DICS -->
  <script>
		document.addEventListener('DOMContentLoaded', domReady);

		function domReady() {
		    new Dics({
          container: document.querySelectorAll('.b-dics')[0],
          linesOrientation: 'horizontal',
          textPosition: 'top',
          arrayBackgroundColorText: ['#FFFFFF', '#000000', '#FFFFFF'],
          arrayColorText: ['#000000', '#FFFFFF', '#000000'],
          linesColor: 'rgb(0,0,0)',
        });
        new Dics({
            container: document.querySelectorAll('.b-dics')[1],
            linesOrientation: 'horizontal',
            textPosition: 'bottom',
            arrayBackgroundColorText: ['#FFFFFF', '#000000', '#FFFFFF'],
            arrayColorText: ['#000000', '#FFFFFF', '#000000'],
            linesColor: 'rgb(0,0,0)',
        });
		}
   </script>

   <!-- Force gif to start at the same time -->
  <script>
  function restartGIFs() {
    const gif_radiance = document.getElementById('gif_radiance');
    const gif_altitude = document.getElementById('gif_altitude');
    
    // Force reload by adding a timestamp
    const timestamp = Date.now();
    gif_radiance.src = `static/videos/video_2s_per_im_radiance_labelled.gif?t=${timestamp}`;
    gif_altitude.src = `static/videos/video_2s_per_im_depth_labelled.gif?t=${timestamp}`;
  }

  // Auto-restart on page load
  window.addEventListener('load', restartGIFs);
  </script>

  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "Sky-NeRF",
    "description": "Article 'Sky-NeRF: Learning 4D Cloud Topography in a Dynamic Neural Radiance Field', in the ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences 2026",
    "author": [
      {
        "@type": "Person",
        "name": "Theïlo Terrisse",
        "affiliation": {
          "@type": "Organization",
          "name": "CS Group, 6 rue Brindejonc des Moulinais, Toulouse, France"
        }
      },
      {
        "@type": "Person",
        "name": "Dawa Derksen",
        "affiliation": {
          "@type": "Organization",
          "name": "CNES, 18 avenue Edouard Belin, Toulouse, France"
        }
      },
      {
        "@type": "Person",
        "name": "David Youssefi",
        "affiliation": {
          "@type": "Organization",
          "name": "CNES, 18 avenue Edouard Belin, Toulouse, France"
        }
      },
      {
        "@type": "Person",
        "name": "Hugo Meric",
        "affiliation": {
          "@type": "Organization",
          "name": "CNES, 18 avenue Edouard Belin, Toulouse, France"
        }
      },
    ],
    "datePublished": "2026-07-04",
    "publisher": {
      "@type": "Organization",
      "name": "ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences"
    },
    "url": "https://TheiloT.github.io",
    "image": "https://TheiloT.github.io/static/images/social_preview.png",
    "keywords": ["Cloud Topography", "Trajectory Estimation", "4D Reconstruction", "Dynamic Neural Radiance Fields", "Physics-Inspired Deep Learning"],
    "abstract": "We present Sky-NeRF, a novel method for cloud topography estimation based on Dynamic Neural Radiance Fields. Similar to NeRF, we propose to model the 3D structure of clouds as a radiance field, encoded in the parameters of a neural representation. Our goal is to reconstruct the 3D geometry, appearance, and motion of the cloud using a stereo-video of high-resolution top of the atmosphere radiance images. In this paper, we evaluate a novel way of modeling the dynamic behavior of clouds, with the goal of extracting added-value physical information regarding the cloud such as advection speed and direction, velocity field and cloud trajectories. We investigate how to include a simple physical prior, advection, into the learning system and evaluate its impact. Our results show that Sky-NeRF is able to provide a more complete 4D reconstruction than traditional stereo-matching-based algorithms. Moreover, thanks to a physics-based interpolation, Sky-NeRF is able to generate coherent new images from unseen viewing angles, and at any time between the observed frames.",
    "citation": "",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://TheiloT.github.io"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Cloud topography"
      },
      {
        "@type": "Thing", 
        "name": "Dynamic Neural Radiance Fields"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "CS Group",
    "url": "https://www.cs-soprasteria.com/en/",
  }
  </script>
</head>
<body>


<!-- Scroll to Top Button -->
<button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
  <i class="fas fa-chevron-up"></i>
</button>

<main id="main-content">
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Sky-NeRF: Learning 4D Cloud Topography in a Dynamic Neural Radiance Field</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">Theïlo Terrisse<sup>1</sup>,</span>
            <span class="author-block">Dawa Derksen<sup>2</sup>,</span>
            <span class="author-block">David Youssefi<sup>2</sup>,</span>
            <span class="author-block">Hugo Meric<sup>2</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <!-- TODO: Replace with your institution and conference/journal info -->
            <span class="author-block"><sup>1</sup>CS Group, <sup>2</sup>CNES<br>XXV ISPRS Congress</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fas fa-file-pdf"></i>
                </span>
                <span>Paper</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%" preload="metadata">
        <source src="static/videos/teaser_video.mp4" type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        From a simulated sequence of 20 images taken by a pair of satellites that perform a fly-by over a cloud scene, Sky-NeRF is able to reconstruct the cloud's geometry and appearance throughout the duration of the fly-by, interpolating between satellite acquisitions.
      </h2>
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We present Sky-NeRF, a novel method for cloud topography estimation based on Dynamic Neural Radiance Fields. Similar to NeRF, we propose to model the 3D structure of clouds as a radiance field, encoded in the parameters of a neural representation. Our goal is to reconstruct the 3D geometry, appearance, and motion of the cloud using a stereo-video of high-resolution top of the atmosphere radiance images. In this paper, we evaluate a novel way of modeling the dynamic behavior of clouds, with the goal of extracting added-value physical information regarding the cloud such as advection speed and direction, velocity field and cloud trajectories. We investigate how to include a simple physical prior, advection, into the learning system and evaluate its impact. Our results show that Sky-NeRF is able to provide a more complete 4D reconstruction than traditional stereo-matching-based algorithms. Moreover, thanks to a physics-based interpolation, Sky-NeRF is able to generate coherent new images from unseen viewing angles, and at any time between the observed frames.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Method overview -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Method overview</h2>
          <div class="item">
            <img src="static/images/global_diagram_with_legend.png" alt="Method overview diagram" loading="lazy"/>
            <h2 class="subtitle has-text-justified">
            <b>Geometrical configuration of the dataset and overview of Sky-NeRF.</b> Drawing inspiration from D-NeRF, At any time \(t\), 3D samples \(X\) are collected by ray casting (a). Each sample is passed to an advection+residual decomposition \(\psi^{\to C}_t = \boldsymbol{u}_{adv} + \hat{\psi}_t^{\to C}\) which maps position \(\boldsymbol{X}\) in ''local'' space at any time \(t\) to position \(\boldsymbol{X}_C\) in a time-independent ''canonical space'' (b), where the 3D opacity and color distributions are encoded by a network \(\psi_x\) (c). The differentiable renderer then blends the predicted samples along the ray to produce a pixel colour (d), compared with the true color through \(\mathcal{L}_{RGB}\) (e). For trajectory estimation, the position \(X'\) of any point \(X_C\) of the canonical space at any time \(t'\) is estimated by \(\psi_t^{\to L}\) which encodes the reverse mapping of \(\psi_t^{\to C}\) (f), supervised through the consistency loss term \(\mathcal{L}_{\to{L}}\) when \(t'=t\) (g).
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End method overview -->


<!-- 3D reconstruction -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">3D reconstruction</h2>
          <div class="item">
            <video poster="" id="tree" controls muted loop height="100%" width="100%" preload="metadata">
                <source src="static/videos/LOA_sequence.mp4" type="video/mp4">
              </video>
            <h2 class="subtitle has-text-centered">
              <b>Input sequence.</b> The input sequence consists of red-band optical images simulated to match the geometrical configuration of the C<sup>3</sup>IEL mission. The views match the positions of two satellite cameras that follow the same fly-by pass over the cloud scene with a baseline of 150km between them. The images are simulated at a rate of one pair every 20s over 180s.
            </h2>
          </div>
          <!-- 3-image slider comparison -->
          <div class="item" style="margin-top: 4rem">
            <div style="display: flex; align-items: center; justify-content: center; gap: 0px">
              <div class="b-dics" style="width: 80%">
                <img src="static/images/gt_pc_tilted.png" alt="Reference">
                <img src="static/images/nerf_pc_tilted.png" alt="Sky-NeRF">
                <img src="static/images/cars_pc_tilted.png" alt="CARS">
              </div>
              <img src="static/images/cc_alt_cbar.png" style="width:13%" alt="Reference">
            </div>
            <h2 class="subtitle has-text-centered">
              <b>3D reconstruction.</b> Sky-NeRF can reconstruct the cloud scene's geometry at any time during the satellite pass. The above clouds are reconstructed 100s after the start of the sequence. Although stereo-vision pipeline CARS (right) keeps a slight advantage in reconstruction accuracy over the cloud top, Sky-NeRF (middle) reconstructs a more complete geometry when compared with the reference produced by the simulation (left).
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End 3D reconstruction -->


<!-- Video synthesis -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3" style="text-align: center">Video synthesis</h2>
          <h2 style="font-size: large">Sky-NeRF can generate intuitive visualizations of the clouds and their development. The videos below were produced by fixing the camera position and unfolding time, then by fixing time and executing a fly-by. As interpolating further from the satellites'positions at a given time makes for a harder problem, in the fixed-position case, reconstruction quality tends to decay towards the temporal extremities of the sequence.</h2>
          <div id="results-carousel" class="carousel results-carousel">
            <div class="item">
              <!-- Fixed-view, time-elapsing video -->
              <!-- <div class="b-dics" style="width: 1000px">
                <img src="static/images/gt_pc_tilted.png" alt="Reference">
                <img src="static/images/nerf_pc_tilted.png" alt="Sky-NeRF">
                <img src="static/images/cars_pc_tilted.png" alt="CARS">
              </div> -->
              <div class="b-dics" style="width: 1000px">
                <img id="gif_radiance" src="static/videos/video_2s_per_im_radiance_labelled.gif" alt="Radiance">
                <img id="gif_altitude" src="static/videos/video_2s_per_im_depth_labelled.gif" alt="Altitude">
              </div>
              <h2 class="subtitle has-text-centered">
                Unfolding time at fixed, nadir position.
              </h2>
            </div>
            <div class="item item-video2">
              <!-- Fixed-time, fly-by video -->
              <video poster="" id="tree" controls muted loop height="100%" preload="metadata">
                <source src="static/videos/fixed-time-pass.mp4" type="video/mp4">
              </video>
              <h2 class="subtitle has-text-centered">
                Fly-by visualization, 90s after the start of the sequence.
              </h2>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End video synthesis -->

<!-- Motion estimation -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3" style="text-align: center">Motion estimation</h2>
          <h2 style="font-size: large">Thanks to its advection module and canonical-to-local mapping network, Sky-NeRF is able to approximate the trajectory field of the cloud between any two points in time, while separating a global-scene advection motion from residual cloud motions.</h2>
          <div id="motion-carousel" class="carousel results-carousel">
            <!-- Example trajectories -->
            <div class="item has-text-centered">
                <img src="static/images/trajectories_side_labelled.png" alt="Trajectory side view">
            </div>
            <div class="item has-text-centered">
              <img src="static/images/trajectories_top_labelled.png" style="height:auto; width:51%" alt="Trajectory top view">
            </div>
          </div>
          <h2 class="subtitle has-text-centered">
            Example trajectory predicted for a surface point on a cloud of the scene, from acquisition <span style="color:red">\(A_1\)</span> to <span style="color: rgb(128, 0, 255)">\(A_{19}\)</span>. Slices of the reference point cloud are shown at three acquisitions. The predicted trajectory is compared with a reference trajectory computed by concatenating Iterative Closest Point transformations between successive acquisitions.
          </h2>
          <hr style="height:1px; background-color:black">
          <div item style="margin-top: 2rem">
            <img src="static/images/advection_module_stats.png" alt="Statistics on estimated advection">
            <h2 class="subtitle has-text-centered">
                On the left, the magnitude of the predicted advection, overlaid to the velocities derived between successive acquisition times from points of the reference point clouds. The vertical profile of the learnt wind learnt is consistent with the average motion of the reference. On the right, the elevation and azimuth of the advection are estimated accurately.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End motion estimation -->

<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@article{terrisse2026skynerf,
        title={Sky-NeRF: Learning 4D Cloud Topography in a Dynamic Neural Radiance Field},
        author={Theïlo Terrisse and Dawa Derksen and David Youssefi and Hugo Meric},
        journal={ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
        volume={TO FILL},
        year={2026},
        pages={TO FILL},
        DOI = {TO FILL}
      }</code></pre>
    </div>
</section>
<!--End BibTex citation -->

<!--Acknowledgements -->
<section class="section hero">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title">Acknowledgments</h2>
        <div class="content has-text-justified">
          <p>
            We gratefully acknowledge the Laboratoire d'Optique Atmosphérique for providing access to the cloud simulation used in this study. We also sincerely thank CNES for supporting this work by granting access to high-performance computing resources at their computing center.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--End acknowledgements -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
